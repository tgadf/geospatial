{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_area{max-height:10000px;overflow:scroll;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 |Anaconda custom (x86_64)| (default, Apr 26 2018, 08:42:37) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Notebook Last Run Initiated: 2018-12-14 09:50:30.051329\n"
     ]
    }
   ],
   "source": [
    "## Basic stuff\n",
    "#%load_ext autoreload\n",
    "#%autoreload\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"\"\"<style>div.output_area{max-height:10000px;overflow:scroll;}</style>\"\"\"))\n",
    "\n",
    "\n",
    "## Python Version\n",
    "import sys\n",
    "print(\"Python: {0}\".format(sys.version))\n",
    "\n",
    "\n",
    "## Install\n",
    "import shapefile\n",
    "import geohash\n",
    "from timeUtils import clock, elapsed\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry import Point\n",
    "from random import uniform\n",
    "from fsUtils import isFile\n",
    "from ioUtils import showSize, saveJoblib, loadJoblib\n",
    "from webUtils import getWebData, getHTML, removeTag\n",
    "from geoUtils import *\n",
    "from geospatialUtils import saveGeoData, getBB, rmZipDir, getGeos\n",
    "import pickle\n",
    "from glob import glob\n",
    "import geopy\n",
    "import requests\n",
    "from os.path import basename,splitext,join\n",
    "from collections import Counter\n",
    "\n",
    "import datetime as dt\n",
    "start = dt.datetime.now()\n",
    "print(\"Notebook Last Run Initiated: \"+str(start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = 7\n",
    "size = 50 # meters\n",
    "basedir = \"/Users/tgadf/Downloads/gasbuddy\"\n",
    "# http://gas-stations.citgo.com/tn/knoxville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time is Fri Dec 14, 2018 12:24:41 for Last Run\n"
     ]
    }
   ],
   "source": [
    "states={}\n",
    "states[\"AL\"] = \"Alabama\"\n",
    "states[\"AK\"] = \"Alaska\"\n",
    "states[\"AZ\"] = \"Arizona\"\n",
    "states[\"AR\"] = \"Arkansas\"\n",
    "states[\"CA\"] = \"California\"\n",
    "states[\"CO\"] = \"Colorado\"\n",
    "states[\"CT\"] = \"Connecticut\"\n",
    "states[\"DE\"] = \"Delaware\"\n",
    "states[\"DC\"] = \"District of Columbia\"\n",
    "states[\"FL\"] = \"Florida\"\n",
    "states[\"GA\"] = \"Georgia\"\n",
    "states[\"ID\"] = \"Idaho\"\n",
    "states[\"IL\"] = \"Illinois\"\n",
    "states[\"IN\"] = \"Indiana\"\n",
    "states[\"IA\"] = \"Iowa\"\n",
    "states[\"KS\"] = \"Kansas\"\n",
    "states[\"KY\"] = \"Kentucky\"\n",
    "states[\"LA\"] = \"Louisiana\"\n",
    "states[\"ME\"] = \"Maine\"\n",
    "states[\"MD\"] = \"Maryland\"\n",
    "states[\"MA\"] = \"Massachusetts\"\n",
    "states[\"MI\"] = \"Michigan\"\n",
    "states[\"MN\"] = \"Minnesota\"\n",
    "states[\"MS\"] = \"Mississippi\"\n",
    "states[\"MO\"] = \"Missouri\"\n",
    "states[\"MT\"] = \"Montana\"\n",
    "states[\"NE\"] = \"Nebraska\"\n",
    "states[\"NV\"] = \"Nevada\"\n",
    "states[\"NH\"] = \"New Hampshire\"\n",
    "states[\"NJ\"] = \"New Jersey\"\n",
    "states[\"NM\"] = \"New Mexico\"\n",
    "states[\"NY\"] = \"New York\"\n",
    "states[\"NC\"] = \"North Carolina\"\n",
    "states[\"ND\"] = \"North Dakota\"\n",
    "states[\"OH\"] = \"Ohio\"\n",
    "states[\"OK\"] = \"Oklahoma\"\n",
    "states[\"OR\"] = \"Oregon\"\n",
    "states[\"PA\"] = \"Pennsylvania\"\n",
    "states[\"RI\"] = \"Rhode Island\"\n",
    "states[\"SC\"] = \"South Carolina\"\n",
    "states[\"SD\"] = \"South Dakota\"\n",
    "states[\"TN\"] = \"Tennessee\"\n",
    "states[\"TX\"] = \"Texas\"\n",
    "states[\"UT\"] = \"Utah\"\n",
    "states[\"VT\"] = \"Vermont\"\n",
    "states[\"VA\"] = \"Virginia\"\n",
    "states[\"WA\"] = \"Washington\"\n",
    "states[\"WV\"] = \"West Virginia\"\n",
    "states[\"WI\"] = \"Wisconsin\"\n",
    "states[\"WY\"] = \"Wyoming\"\n",
    "_, _ = clock(\"Last Run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-608eee7d2761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msavename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{0}.html\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mgetWebData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuburl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museSafari\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/site-packages/utils-0.0.1-py3.6.egg/webUtils.py\u001b[0m in \u001b[0;36mgetWebData\u001b[0;34m(base, suburl, extra, savename, dtime, useSafari, debug)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSafariURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/site-packages/utils-0.0.1-py3.6.egg/webUtils.py\u001b[0m in \u001b[0;36mgetURL\u001b[0;34m(url, savename, debug)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0msaveJoblib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#pickle.dump(content, open(savename, \"w\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/census/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "for abbr,name in states.items():\n",
    "    url = \"https://www.allgasstations.com/{0}/\".format(abbr)\n",
    "    savename = join(basedir, \"{0}.html\".format(abbr))\n",
    "    if not isFile(savename):\n",
    "        getWebData(base=url, suburl=None, dtime=5, useSafari=False, savename=savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for abbr,name in states.items():\n",
    "    filename = \"/Users/tgadf/Downloads/ags/{0}.html\".format(abbr)\n",
    "    bsdata   = getHTML(loadJoblib(filename))\n",
    "    for h2 in bsdata.findAll(\"a\"):        \n",
    "        attrs = h2.attrs\n",
    "        href  = attrs['href']\n",
    "        if not href.startswith(\"/\"):\n",
    "            continue\n",
    "        url = \"https://www.allgasstations.com/{0}\".format(href)\n",
    "        savename = \"/Users/tgadf/Downloads/ags/indiv/{0}.html\".format(href[1:-1].replace(\"/\", \"_\"))\n",
    "        if not isFile(savename):\n",
    "            getWebData(base=url, suburl=None, dtime=5, useSafari=False, savename=savename)\n",
    "            sleep(0.33)\n",
    "        \n",
    "    #print(bsdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "addresses={}\n",
    "for abbr,name in states.items():\n",
    "    files = glob(\"/Users/tgadf/Downloads/ags/indiv/{0}_*.html\".format(abbr))\n",
    "    addresses[abbr] = []\n",
    "    for filename in files:\n",
    "        bsdata = getHTML(loadJoblib(filename))\n",
    "        for i, div in enumerate(bsdata.findAll(\"div\")):\n",
    "            if div.attrs.get('class') is None:\n",
    "                continue\n",
    "            if 'col' in div.attrs['class']:\n",
    "                for d in div.findAll(\"div\"):\n",
    "                    tmp = removeTag(line=d, tag='a')\n",
    "                    tmp = removeTag(line=tmp, tag='i')                    \n",
    "                    address = tmp.text\n",
    "                    addresses[abbr].append(address)\n",
    "    print(\"Found {0} stations in {1}\".format(len(addresses[abbr]), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJoblib(addresses, \"/Users/tgadf/Downloads/ags/stations.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Pass for Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "geolocator = Nominatim(user_agent=\"tgadf\")\n",
    "addresses  = loadJoblib(\"/Users/tgadf/Downloads/ags/stations.p\")\n",
    "results = {}\n",
    "for abbr,lookups in addresses.items():\n",
    "    results[abbr] = {}\n",
    "    for la, address in enumerate(lookups):\n",
    "        savename = \"/Users/tgadf/Downloads/ags/{0}_{1}_results.p\".format(abbr,la)\n",
    "        if isFile(savename):\n",
    "            continue\n",
    "        vals = address.split(\"\\n\")\n",
    "        for iv,val in enumerate(vals):\n",
    "            if len(val) < 3:\n",
    "                continue\n",
    "            print(\"--> {0}/{1}\\t{2}/{3}\\t{4}\".format(la+1,len(lookups),iv+1,len(vals),val))\n",
    "            try:\n",
    "                location = geolocator.geocode(val)\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                print(location.address,location.latitude, location.longitude)\n",
    "            except:\n",
    "                continue\n",
    "            results[abbr][val] = [location.latitude, location.longitude]\n",
    "            sleep(1)\n",
    "            \n",
    "        saveJoblib(results, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = \"919 East Dimond Boulevard Anchorage, AK 99515\"\n",
    "location = geolocator.geocode(val)\n",
    "print(location.address)\n",
    "print((location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check For Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "geolocator = Nominatim(user_agent=\"tgadf\")\n",
    "addresses  = loadJoblib(\"/Users/tgadf/Downloads/ags/stations.p\")\n",
    "results = {}\n",
    "for abbr,lookups in addresses.items():\n",
    "    print(\"===> {0}\".format(abbr))\n",
    "    results[abbr] = {}\n",
    "    for la, address in enumerate(lookups):\n",
    "        savename = \"/Users/tgadf/Downloads/ags/{0}_{1}_results.p\".format(abbr,la)\n",
    "        resave   = False\n",
    "        if isFile(savename):\n",
    "            results = loadJoblib(savename)\n",
    "        else:\n",
    "            continue\n",
    "                \n",
    "        vals = address.split(\"\\n\")\n",
    "        for iv,val in enumerate(vals):\n",
    "            if len(val) < 3:\n",
    "                continue\n",
    "                \n",
    "            if results[abbr].get(val) is None:\n",
    "                print(\"--> {0}/{1}\\t{2}/{3}\\t{4}\".format(la+1,len(lookups),iv+1,len(vals),val))\n",
    "                try:\n",
    "                    val = val.replace(\"USHighway \", \"US\")\n",
    "                    location = geolocator.geocode(val)\n",
    "                    print(location.address,location.latitude, location.longitude)\n",
    "                    resave = True\n",
    "                except:\n",
    "                    continue\n",
    "                results[abbr][val] = [location.latitude, location.longitude]\n",
    "                sleep(1)\n",
    "\n",
    "        if resave == True:\n",
    "            print(\"Resaving {0}\".format(savename))\n",
    "            saveJoblib(results, savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 \t Alabama\n",
      "685 \t Alaska\n",
      "1108 \t Arizona\n",
      "1416 \t Arkansas\n",
      "4591 \t California\n",
      "5052 \t Colorado\n",
      "5748 \t Connecticut\n",
      "5838 \t Delaware\n",
      "5921 \t District of Columbia\n",
      "7227 \t Florida\n",
      "7858 \t Georgia\n",
      "7939 \t Idaho\n",
      "9352 \t Illinois\n",
      "9938 \t Indiana\n",
      "10342 \t Iowa\n",
      "10749 \t Kansas\n",
      "11239 \t Kentucky\n",
      "11979 \t Louisiana\n",
      "12223 \t Maine\n",
      "13153 \t Maryland\n",
      "14294 \t Massachusetts\n",
      "15677 \t Michigan\n",
      "16238 \t Minnesota\n",
      "16573 \t Mississippi\n",
      "17170 \t Missouri\n",
      "17284 \t Montana\n",
      "17565 \t Nebraska\n",
      "17723 \t Nevada\n",
      "17938 \t New Hampshire\n",
      "18991 \t New Jersey\n",
      "19262 \t New Mexico\n",
      "20757 \t New York\n",
      "21696 \t North Carolina\n",
      "21839 \t North Dakota\n",
      "23042 \t Ohio\n",
      "23425 \t Oklahoma\n",
      "23913 \t Oregon\n",
      "24905 \t Pennsylvania\n",
      "25088 \t Rhode Island\n",
      "25563 \t South Carolina\n",
      "25685 \t South Dakota\n",
      "26539 \t Tennessee\n",
      "28211 \t Texas\n",
      "28393 \t Utah\n",
      "28531 \t Vermont\n",
      "29536 \t Virginia\n",
      "30314 \t Washington\n",
      "30559 \t West Virginia\n",
      "31461 \t Wisconsin\n",
      "31555 \t Wyoming\n",
      "  --> This file is 1.1MB.\n"
     ]
    }
   ],
   "source": [
    "locations = {}\n",
    "from glob import glob\n",
    "for abbr,statename in states.items():\n",
    "    files = glob(\"/Users/tgadf/Downloads/ags/{0}_*_results.p\".format(abbr))\n",
    "    for filename in files:\n",
    "        if isFile(filename):\n",
    "            results = loadJoblib(filename)\n",
    "        else:\n",
    "            raise ValueError(\"Could not open {0}\".format(filename))\n",
    "            \n",
    "        for state,values in results.items():\n",
    "            for name,location in values.items():\n",
    "                locations[name] = location\n",
    "    print(len(locations),'\\t',statename)\n",
    "\n",
    "savename = \"/Users/tgadf/Downloads/ags/locations.p\"\n",
    "saveJoblib(locations, savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Geohashs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 locations and 2798 geos\n",
      "Found 2000 locations and 5546 geos\n",
      "Found 3000 locations and 8265 geos\n",
      "Found 4000 locations and 10959 geos\n",
      "Found 5000 locations and 13680 geos\n",
      "Found 6000 locations and 16454 geos\n",
      "Found 7000 locations and 19081 geos\n",
      "Found 8000 locations and 21766 geos\n",
      "Found 9000 locations and 24640 geos\n",
      "Found 10000 locations and 27500 geos\n",
      "Found 11000 locations and 30408 geos\n",
      "Found 12000 locations and 33111 geos\n",
      "Found 13000 locations and 35752 geos\n",
      "Found 14000 locations and 38510 geos\n",
      "Found 15000 locations and 41310 geos\n",
      "Found 16000 locations and 44174 geos\n",
      "Found 17000 locations and 47014 geos\n",
      "Found 18000 locations and 49956 geos\n",
      "Found 19000 locations and 52794 geos\n",
      "Found 20000 locations and 55569 geos\n",
      "Found 21000 locations and 58345 geos\n",
      "Found 22000 locations and 61256 geos\n",
      "Found 23000 locations and 63966 geos\n",
      "Found 24000 locations and 66811 geos\n",
      "Found 25000 locations and 69662 geos\n",
      "Found 26000 locations and 72453 geos\n",
      "Found 27000 locations and 75199 geos\n",
      "Found 28000 locations and 77881 geos\n",
      "Found 29000 locations and 80603 geos\n",
      "Found 30000 locations and 83373 geos\n",
      "Found 31000 locations and 86265 geos\n",
      "Found 31555 locations and 4 geos\n",
      "Writing /Users/tgadf/Downloads/ags/geomap-7-AGS.p\n",
      "  --> This file is 591.0kB.\n"
     ]
    }
   ],
   "source": [
    "filename = \"/Users/tgadf/Downloads/ags/locations.p\"\n",
    "locations = loadJoblib(filename)\n",
    "\n",
    "geomap = {}\n",
    "nl   = 0\n",
    "for name,location in locations.items():\n",
    "    lat0 = location[0]\n",
    "    lng0 = location[1]\n",
    "    \n",
    "    dLat = convertMetersToLat(size)\n",
    "    dLng = convertMetersToLong(size, lat0)\n",
    "    nl  += 1\n",
    "    \n",
    "    for i in [1, 0, -1]:\n",
    "        for j in [1, 0, -1]:\n",
    "            lat = lat0 + i*dLat\n",
    "            lng = lng0 + j*dLng\n",
    "            \n",
    "            geo = geohash.encode(latitude=lat, longitude=lng, precision=prec)\n",
    "            geomap[geo] = {\"AGSFuel\": 1}\n",
    "            \n",
    "    for geo in geomap.keys():\n",
    "        geomap[geo] = dict(geomap[geo])            \n",
    "            \n",
    "            \n",
    "    if nl % 1000 == 0:\n",
    "        print(\"Found {0} locations and {1} geos\".format(nl, len(geomap)))\n",
    "\n",
    "\n",
    "print(\"Found {0} locations and {1} geos\".format(nl, len(geos)))\n",
    "fname=\"/Users/tgadf/Downloads/ags/geomap-{0}-AGS.p\".format(prec)\n",
    "print(\"Writing {0}\".format(fname))\n",
    "saveJoblib(geomap, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoSpatial Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (if needed)\n",
    "# geos = loadJoblib(\"/Users/tgadf/Downloads/ags/geomap-{0}-AGS.p\".format(prec)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import PolyLine, CircleMarker, Circle, Marker, Icon, FeatureGroup, Map, LayerControl\n",
    "import geohash\n",
    "\n",
    "def addCircles(geos, m, init=None, maxDist=None, debug=False):\n",
    "    cols = ['darkgreen']\n",
    "\n",
    "    toPlot = []\n",
    "    for geo in geos:\n",
    "        com = geohash.decode_exactly(geo)[:2]\n",
    "        if init is not None:\n",
    "            if getDist(com, init) < maxDist:\n",
    "                toPlot = getBB(geo, istuple=True)\n",
    "                PolyLine(toPlot, color='blue', weight=1, opacity=1).add_to(m)\n",
    "        else:\n",
    "            Circle(com, color=cols[0], radius=rad, fill=True, fill_color=cols[0], weight=1, opacity=0).add_to(m)\n",
    "        \n",
    "def createMap(init=None):\n",
    "    if init is not None:\n",
    "        m = Map(location=[init[0], init[1]], zoom_start=10)\n",
    "    else:\n",
    "        m = Map(location=[40, -95], zoom_start=4)\n",
    "        \n",
    "    return m        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = init=(36, -84)\n",
    "m = createMap(init)\n",
    "addCircles(geos, m=m, init=init, maxDist=100000)\n",
    "m.save(\"/Users/tgadf/Downloads/ags/ags-map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
