{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Last Run Initiated: 2018-09-20 11:30:26.394143\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    div.output_area{\n",
       "        max-height:10000px;\n",
       "        overflow:scroll;\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "start = dt.datetime.now()\n",
    "print(\"Notebook Last Run Initiated: \"+str(start))\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"\"\"<style>\n",
    "    div.output_area{\n",
    "        max-height:10000px;\n",
    "        overflow:scroll;\n",
    "    }\n",
    "</style>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Current Time is Thu Sep 20, 2018 11:30:26 for Begin\n",
      "3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math, random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists,join\n",
    "import seaborn as sns\n",
    "from scipy.stats import kendalltau\n",
    "from haversine import haversine\n",
    "import pygeohash as geohash\n",
    "import sys\n",
    "\n",
    "from modelio import saveData, loadData, saveSparkData, appendSparkData, saveJoblib, loadJoblib\n",
    "from timeUtils import clock, elapsed, getTimeSuffix, getDateTime, addDays, printDateTime, getFirstLastDay\n",
    "\n",
    "\n",
    "clock()\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCities():\n",
    "    cities={}\n",
    "    cities['naperville'] = {\"lat\": 41.750839, \"long\": -88.153535, \"radius\": 0.05}\n",
    "    cities['knoxville']  = {'lat': 35.964668, 'long': -83.926453, 'radius': 0.15}\n",
    "    cities['evanston']   = {'lat': 42.041166, 'long': -87.690163, 'radius': 0.05}\n",
    "    cities['wrigley']    = {'lat': 41.948437, 'long': -87.655334, 'radius': 0.03} # Wrigley Field\n",
    "    cities['alexandria'] = {'lat': 38.80472,  'long': -77.04722, 'radius': 0.075}  # Alexandria, VA\n",
    "    cities['dallas']     = {'long': -97.04044, 'lat': 32.897480, 'radius': 0.15}\n",
    "    cities['urbana']     = {'long': -88.24338, 'lat': 40.116421, 'radius': 0.15}\n",
    "    cities['portjeff']   = {'long': -73.06927, 'lat': 40.946487, 'radius': 0.15}\n",
    "    cities['r4h']        = {'lat': 38.88184,  'long': -77.10806, 'radius': 0.05} # r4h\n",
    "    cities['r4h']        = {'lat': 41.76,  'long': -88.3200715, 'radius': 0.05} # r4h\n",
    "    return cities\n",
    "\n",
    "colors = [ 'red', 'blue', 'gray', 'darkred', 'lightred', 'orange', 'beige', 'green', 'darkgreen', 'lightgreen', 'darkblue', 'lightblue', 'purple', 'darkpurple', 'lightgray']\n",
    "    \n",
    "def distHash(gcode1, gcode2):\n",
    "    \"\"\"\n",
    "    distHash(gcode1, gcode2)\n",
    "\n",
    "    inputs: gcode1 (geohash), gcode2 (geohash)\n",
    "    outputs: distance (km)\n",
    "    \"\"\"\n",
    "    pnt1 = geohash.decode_exactly(gcode1)[:2]\n",
    "    pnt2 = geohash.decode_exactly(gcode2)[:2]\n",
    "    dist = haversine(pnt1, pnt2)\n",
    "    return dist\n",
    "\n",
    "def getPOIByCity(cityname):\n",
    "    poi = loadJoblib('poi-7.p')\n",
    "    cities = getCities()\n",
    "    for city,citydata in cities.items():\n",
    "        if city != cityname:\n",
    "            continue\n",
    "        print(\"City --> {0}\".format(city))\n",
    "        geocity = geohash.encode(citydata['lat'], citydata['long'], precision=7)\n",
    "        poicity = {}\n",
    "        for k,v in poi.items():\n",
    "            poicity[k] = set()\n",
    "            for geo in v:\n",
    "                try:\n",
    "                    dist = distHash(geocity, geo)\n",
    "                except:\n",
    "                    continue\n",
    "                if dist < citydata['radius']*111:\n",
    "                    poicity[k].add(geo)\n",
    "            print(\"  Keeping {0} out of {1}\".format(len(poicity[k]), len(v)))\n",
    "        print(\"--> {0}\".format(city))\n",
    "        saveJoblib(poicity, 'poi-{0}.p'.format(city))\n",
    "#getPOIByCity('r4h')\n",
    "\n",
    "city='evanston'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoundary(points):    \n",
    "    from scipy.spatial import ConvexHull\n",
    "    hull     = ConvexHull(points)\n",
    "    boundary = [points[x] for x in hull.vertices]\n",
    "    return boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skim Geomaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading geomap-7-HEREPOI.p\n",
      "  --> Found 186738 geos\n",
      "  -->  Keep 129 geos\n",
      "  --> This file is 1.2kB.\n",
      "Loading geomap-7-HighwayA.p\n",
      "  --> Found 1311011 geos\n",
      "Loading geomap-7-HighwayB.p\n",
      "  --> Found 924506 geos\n",
      "Loading geomap-7-HighwayC.p\n",
      "  --> Found 1076021 geos\n",
      "  -->  Keep 9 geos\n",
      "  --> This file is 126B.\n",
      "Loading geomap-7-Industry.p\n",
      "  --> Found 9587 geos\n",
      "Loading geomap-7-InterstateA.p\n",
      "  --> Found 253770 geos\n",
      "Loading geomap-7-InterstateB.p\n",
      "  --> Found 152055 geos\n",
      "Loading geomap-7-InterstateC.p\n",
      "  --> Found 194921 geos\n",
      "Loading geomap-7-MajorRdA.p\n",
      "  --> Found 1754319 geos\n",
      "Loading geomap-7-MajorRdB.p\n",
      "  --> Found 1295815 geos\n",
      "Loading geomap-7-MajorRdC.p\n",
      "  --> Found 1201250 geos\n",
      "  -->  Keep 2312 geos\n",
      "  --> This file is 16.9kB.\n",
      "Loading geomap-7-pofwOSM.p\n",
      "  --> Found 257804 geos\n",
      "  -->  Keep 197 geos\n",
      "  --> This file is 1.4kB.\n",
      "Loading geomap-7-poisOSM.p\n",
      "  --> Found 2828691 geos\n",
      "  -->  Keep 1253 geos\n",
      "  --> This file is 10.6kB.\n",
      "Loading geomap-7-powfOSM.p\n",
      "  --> Found 0 geos\n",
      "Loading geomap-7-Rail.p\n",
      "  --> Found 1461572 geos\n",
      "  -->  Keep 153 geos\n",
      "  --> This file is 1.2kB.\n",
      "Loading geomap-7-Schools.p\n",
      "  --> Found 122236 geos\n",
      "  -->  Keep 71 geos\n",
      "  --> This file is 576B.\n",
      "Loading geomap-7-StateRteA.p\n",
      "  --> Found 1941654 geos\n",
      "Loading geomap-7-StateRteB.p\n",
      "  --> Found 1118374 geos\n",
      "Loading geomap-7-StateRteC.p\n",
      "  --> Found 1089197 geos\n",
      "  -->  Keep 3 geos\n",
      "  --> This file is 70B.\n",
      "Loading geomap-7-Terminals.p\n",
      "  --> Found 509020 geos\n",
      "  -->  Keep 2 geos\n",
      "  --> This file is 62B.\n",
      "Loading geomap-7-trafficOSM.p\n",
      "  --> Found 815918 geos\n",
      "  -->  Keep 628 geos\n",
      "  --> This file is 4.3kB.\n",
      "Loading geomap-7-transportOSM.p\n",
      "  --> Found 107213 geos\n",
      "  -->  Keep 406 geos\n",
      "  --> This file is 2.9kB.\n",
      "Loading geomap-7-USRteA.p\n",
      "  --> Found 591948 geos\n",
      "Loading geomap-7-USRteB.p\n",
      "  --> Found 474965 geos\n",
      "Loading geomap-7-USRteC.p\n",
      "  --> Found 473534 geos\n",
      "  -->  Keep 26 geos\n",
      "  --> This file is 216B.\n",
      "Loading geomap-7-Venues.p\n",
      "  --> Found 677 geos\n",
      "  -->  Keep 2 geos\n",
      "  --> This file is 102B.\n"
     ]
    }
   ],
   "source": [
    "prec=7\n",
    "from glob import glob\n",
    "from os.path import join, basename\n",
    "files = glob(\"geomap-{0}-*.p\".format(prec))\n",
    "\n",
    "import folium\n",
    "cities = getCities()\n",
    "pnt2=(cities[city]['lat'], cities[city]['long'])\n",
    "\n",
    "from os import mkdir\n",
    "savedir = \"geoskims/{0}\".format(city)\n",
    "try:\n",
    "    mkdir(savedir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "distMax = 5\n",
    "import pickle\n",
    "from modelio import saveJoblib\n",
    "for ifile in files:\n",
    "    print(\"Loading {0}\".format(ifile))\n",
    "    data = pickle.load(open(ifile, \"rb\"))\n",
    "    print(\"  --> Found {0} geos\".format(len(data)))\n",
    "    save = {}\n",
    "    for geo, rec in data.items():\n",
    "        lat,long = geohash.decode_exactly(geo)[:2]\n",
    "        pnt1 = (lat, long)\n",
    "        dist = haversine(pnt1, pnt2)\n",
    "        if dist > distMax:\n",
    "            continue\n",
    "        save[geo] = rec\n",
    "    if len(save) > 0:\n",
    "        print(\"  -->  Keep {0} geos\".format(len(save)))    \n",
    "        savename = join(savedir, basename(ifile))\n",
    "        #print(\"Saving {0} geos to {1}\".format(len(save), savename))\n",
    "        saveJoblib(save, savename)\n",
    "    #pickle.dump(save, open(savename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add To Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2728 \t Car\n",
      "83 \t College\n",
      "2183 \t Commerce\n",
      "129 \t HEREPOI\n",
      "9 \t HighwayC\n",
      "1 \t Industry\n",
      "1406 \t InterstateC\n",
      "2312 \t MajorRdC\n",
      "197 \t pofwOSM\n",
      "1253 \t poisOSM\n",
      "153 \t Rail\n",
      "71 \t Schools\n",
      "3 \t StateRteC\n",
      "2 \t Terminals\n",
      "628 \t trafficOSM\n",
      "406 \t transportOSM\n",
      "26 \t USRteC\n",
      "2 \t Venues\n"
     ]
    }
   ],
   "source": [
    "skimdata = {}\n",
    "prec=7\n",
    "from glob import glob\n",
    "from modelio import loadJoblib\n",
    "from os.path import join, basename, splitext\n",
    "from os import remove\n",
    "files = glob(\"geoskims/{0}/*.p\".format(city))\n",
    "for ifile in files:\n",
    "    name = splitext(basename(ifile))[0].split('-')[-1]\n",
    "    skimdata[name] = loadJoblib(ifile)    \n",
    "    if len(skimdata[name]) == 0:\n",
    "        remove(ifile)\n",
    "        continue\n",
    "    print(len(skimdata[name]),'\\t',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [ 'red', 'blue', 'gray', 'darkred', 'lightred', 'orange', 'beige', 'green', 'darkgreen', 'lightgreen', 'darkblue', 'lightblue', 'purple', 'darkpurple', 'pink', 'cadetblue', 'lightgray', 'black' ]\n",
    "\n",
    "def addData(m, dc, name, geovalues, cmap, radius=75, useBB=False, fill=False, useIcon=False):\n",
    "    from timeUtils import clock, elapsed\n",
    "    from modelio import saveJoblib, loadJoblib\n",
    "    from folium import PolyLine, CircleMarker, Circle, Marker, Icon, FeatureGroup\n",
    "    start,cmt = clock(\"Adding to folium\")\n",
    "    \n",
    "    feature_group = FeatureGroup(name=name)\n",
    "\n",
    "    for geo,weight in geovalues.items():\n",
    "        color='gray'\n",
    "        if isinstance(cmap, dict):\n",
    "            for val,col in cmap.items():\n",
    "                if weight.get(val) is not None:\n",
    "                    color=col\n",
    "                    break\n",
    "        else:\n",
    "            color=cmap\n",
    "        if useBB:\n",
    "            points = dc.getBB(geo, istuple=True)\n",
    "            PolyLine(points, color=color, weight=len(weight), opacity=1, popup=\",\".join(weight.keys())).add_to(feature_group)\n",
    "        elif useIcon:\n",
    "            center = dc.getCenter(geo)\n",
    "            Marker(center, icon=Icon(color='blue', icon_color='white', icon=col, angle=0, prefix='fa'), popup=\",\".join(weight.keys())).add_to(feature_group)\n",
    "        else:\n",
    "            if fill:\n",
    "                center = dc.getCenter(geo)\n",
    "                Circle(center, color=color, radius=radius, fill=True, fill_color=color, weight=len(weight)/2, opacity=1, popup=\", \".join(weight.keys())).add_to(feature_group)\n",
    "            else:\n",
    "                center = dc.getCenter(geo)\n",
    "                Circle(center, color=color, radius=radius, weight=len(weight)/2, opacity=1, popup=\", \".join(weight.keys())).add_to(feature_group)\n",
    "                \n",
    "    \n",
    "    feature_group.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time is Thu Sep 20, 2018 13:29:10 for Adding to folium\n",
      "Current Time is Thu Sep 20, 2018 13:29:10 for Adding to folium\n",
      "Current Time is Thu Sep 20, 2018 13:29:10 for Adding to folium\n",
      "Current Time is Thu Sep 20, 2018 13:29:11 for Adding to folium\n",
      "Current Time is Thu Sep 20, 2018 13:29:11 for Adding to folium\n",
      "Current Time is Thu Sep 20, 2018 13:29:11 for Adding to folium\n",
      "Current Time is Thu Sep 20, 2018 13:29:11 for Adding to folium\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<folium.map.LayerControl at 0x1a4e29ee48>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from collections import OrderedDict\n",
    "cities = getCities()\n",
    "pnt2=(cities[city]['lat'], cities[city]['long'])\n",
    "m = folium.Map(location=list(pnt2), zoom_start=13)\n",
    "from geoClusteringPlots import drawClusters\n",
    "dc = drawClusters()\n",
    "\n",
    "\n",
    "cmap = OrderedDict({'parking': 'cadetblue', 'fuel': 'orange'})\n",
    "addData(m, dc, \"Traffic\", skimdata['trafficOSM'], cmap, useBB=True)\n",
    "\n",
    "cmap = OrderedDict({'entertainment': 'darkred', 'college': 'darkgreen', 'municipal': 'blue', 'attraction': 'green', 'grocery': 'pink', 'auto': 'beige'})\n",
    "addData(m, dc, \"POI\", skimdata['poisOSM'], cmap, radius=75)\n",
    "\n",
    "cmap = OrderedDict({'railstation': 'darkpurple', 'busstop': 'darkpurple'})\n",
    "addData(m, dc, \"Transport\", skimdata['transportOSM'], cmap, radius=60, fill=True)\n",
    "\n",
    "addData(m, dc, \"HERE\", skimdata['HEREPOI'], cmap='lightblue', radius=45, fill=True)\n",
    "\n",
    "addData(m, dc, \"Interstate\", skimdata['InterstateC'], cmap='darkgreen', useBB=True)\n",
    "\n",
    "addData(m, dc, \"Religious\", skimdata['pofwOSM'], cmap='red', radius=30, fill=True)\n",
    "\n",
    "addData(m, dc, \"Terminals\", skimdata['Terminals'], cmap='darkred', useBB=True)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "#cmap = OrderedDict({'PublicSchools': 'green', 'PrivateSchools': 'green'})\n",
    "#addData(m, dc, skimdata['Schools'], cmap, radius=60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"{0}.html\".format(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(skimdata['poisOSM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artwork', 'bakery', 'bank', 'bar', 'beautyshop', 'bicycleshop',\n",
       "       'bookshop', 'cafe', 'campsite', 'cardealership', 'carwash', 'chemist',\n",
       "       'clothes', 'college', 'communitycentre', 'convenience', 'dentist',\n",
       "       'departmentstore', 'doityourself', 'drinkingwater', 'fastfood',\n",
       "       'firestation', 'fountain', 'furnitureshop', 'golfcourse', 'graveyard',\n",
       "       'hairdresser', 'hospital', 'hotel', 'jeweller', 'kindergarten',\n",
       "       'laundry', 'library', 'mall', 'memorial', 'mobilephoneshop', 'museum',\n",
       "       'optician', 'outdoorshop', 'park', 'pharmacy', 'pitch', 'playground',\n",
       "       'police', 'postbox', 'postoffice', 'pub', 'publicbuilding',\n",
       "       'restaurant', 'school', 'shelter', 'shoeshop', 'sportscentre',\n",
       "       'sportsshop', 'stadium', 'stationery', 'supermarket', 'swimmingpool',\n",
       "       'theatre', 'toilet', 'tower', 'townhall', 'toyshop', 'track',\n",
       "       'veterinary', 'viewpoint', 'watertower'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastfood=[\"cafe\", \"bakery\", \"\"]\n",
    "slowfood=[\"pub\", \"bar\", \"restaurant\"]\n",
    "retail=[\"bakery\", \"cafe\"]\n",
    "recreation=[\"campsite\", \"track\", \"golfcourse\", \"swimmingpool\", \"playground\", \"stadium\", \"sportscentre\"]\n",
    "medical=[\"veterinary\", \"hospital\", \"dentist\", \"optician\", \"pharmacy\"]\n",
    "municipal=[\"firestation\", \"police\", \"postoffice\", \"publicbuilding\", \"communitycentre\"]\n",
    "school=[\"school\", \"kindergarten\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
