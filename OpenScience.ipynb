{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_area{max-height:10000px;overflow:scroll;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 |Anaconda custom (x86_64)| (default, Apr 26 2018, 08:42:37) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Notebook Last Run Initiated: 2018-11-15 11:37:53.220897\n"
     ]
    }
   ],
   "source": [
    "## Basic stuff\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"\"\"<style>div.output_area{max-height:10000px;overflow:scroll;}</style>\"\"\"))\n",
    "\n",
    "\n",
    "## Python Version\n",
    "import sys\n",
    "print(\"Python: {0}\".format(sys.version))\n",
    "\n",
    "\n",
    "## Install\n",
    "import shapefile\n",
    "import geohash\n",
    "from timeUtils import clock, elapsed\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry import Point\n",
    "from random import uniform\n",
    "from fsUtils import isFile\n",
    "from ioUtils import showSize, saveJoblib\n",
    "from geoUtils import *\n",
    "from geospatialUtils import saveGeoData, getBB, rmZipDir, getShapeFileInfo, getShapeIter, getGeos\n",
    "import pickle\n",
    "from glob import glob\n",
    "from os.path import basename,splitext,join\n",
    "from collections import Counter\n",
    "\n",
    "import datetime as dt\n",
    "start = dt.datetime.now()\n",
    "print(\"Notebook Last Run Initiated: \"+str(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Params\n",
    "prec=7\n",
    "mainkey=\"OpenScience\"\n",
    "basedir=\"/Users/tgadf/Downloads/OpenScience\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseOS(dirval, prec):\n",
    "    from os.path import basename, dirname, join, splitext\n",
    "    from glob import glob\n",
    "    from collections import Counter\n",
    "    useUnique = False\n",
    "    osmpath   = dirval\n",
    "    osms      = [splitext(basename(x))[0] for x in glob(join(osmpath, \"*.shp\"))]\n",
    "    if len(osms) == 0:\n",
    "        osms      = [splitext(basename(x))[0] for x in glob(join(osmpath, \"*\", \"*.shp\"))]\n",
    "        if len(osms) > 0:\n",
    "            osmpath = glob(join(osmpath, \"*\"))[0]\n",
    "    if len(osms) == 0:\n",
    "        print(\"There are no shape files in {0}\".format(osmpath))\n",
    "        return None\n",
    "    print(\"Directory: {0}\".format(osmpath))\n",
    "    print(\"      OSM: {0}\".format(osms))\n",
    "    blgCntr   = Counter()\n",
    "    nameCntr  = Counter()\n",
    "    nameLookup = {}\n",
    "    \n",
    "    \n",
    "    shapeData   = {}\n",
    "    geoShapeMap = {}\n",
    "    ngeos     = 0\n",
    "    totalgeos = 0\n",
    "    show      = False\n",
    "    cntr      = Counter()\n",
    "        \n",
    "    for osm in osms:\n",
    "        print(osm)\n",
    "        shapeval = osm\n",
    "        \n",
    "        files = glob(join(basedir, \"{0}-{1}*\".format(osm, prec)))\n",
    "        if len(files) > 0:\n",
    "            print(\"Already processed this one...\")\n",
    "            #continue\n",
    "\n",
    "            \n",
    "        ## Standard Shape File Reader\n",
    "        shapedir = join(osmpath, osm)\n",
    "        sf       = getShapeIter(shapedir)\n",
    "        retval   = getShapeFileInfo(sf)\n",
    "        fields   = retval[\"Fields\"]\n",
    "        Nshapes  = retval[\"Num\"]\n",
    "\n",
    "        start,cmt = clock(\"\\n\\nAnalyzing {0}\\t{1}\".format(shapeval, Nshapes))\n",
    "        if show:\n",
    "            print(\"Fields -> {0}\".format(fields))\n",
    "\n",
    "            \n",
    "        ## Interate over shapes\n",
    "        irec = -1\n",
    "        for shapeRec in sf.iterShapeRecords():\n",
    "            irec += 1\n",
    "            if irec % 2500 == 0 and irec > 0:\n",
    "                if True:\n",
    "                    print(\"Processed {0}/{1} records. Found {2} geos so far...\".format(irec, Nshapes, ngeos))\n",
    "\n",
    "            record = shapeRec.record\n",
    "            shape  = shapeRec.shape\n",
    "            points = shape.points\n",
    "            \n",
    "            fclass = None\n",
    "            fclass = osm\n",
    "            if False:\n",
    "                if osm.startswith(\"Arenas\") is True:\n",
    "                    fclass = record[19]\n",
    "                    if fclass.startswith(\"Elementary\") is True:\n",
    "                        fclass=\"PublicSchool\"\n",
    "                    else:\n",
    "                        raise ValueError(\"Don't understand {0} for {1}\".format(fclass, osm))\n",
    "                    geoid  = fclass\n",
    "                if osm == \"PublicSchools\":\n",
    "                    fclass = record[19]\n",
    "                    if fclass.startswith(\"Elementary\") is True:\n",
    "                        fclass=\"PublicSchool\"\n",
    "                    else:\n",
    "                        raise ValueError(\"Don't understand {0} for {1}\".format(fclass, osm))\n",
    "                    geoid  = fclass\n",
    "                if osm == \"PrivateSchools\":\n",
    "                    fclass = record[19]\n",
    "                    if fclass.startswith(\"Elementary\") is True:\n",
    "                        fclass=\"PrivateSchool\"\n",
    "                    else:\n",
    "                        raise ValueError(\"Don't understand {0} for {1}\".format(fclass, osm))\n",
    "                    geoid  = fclass\n",
    "                if osm == \"CollegesUniversities\":\n",
    "                    fclass = record[18]\n",
    "                    if fclass.startswith(\"Colleges\") is True:\n",
    "                        fclass=\"University\"\n",
    "                    elif fclass.startswith(\"Junior\") is True:\n",
    "                        fclass=\"JuniorCollege\"\n",
    "                    elif fclass.find(\"Trade Schools\") != -1:\n",
    "                        fclass=\"Trade\"\n",
    "                    elif fclass.find(\"Cosmetology\") != -1:\n",
    "                        fclass=\"Cosmetology\"\n",
    "                    elif fclass.startswith(\"Business\") is True:\n",
    "                        fclass=\"Business\"\n",
    "                    elif fclass.find(\"Fine Arts\") != -1:\n",
    "                        fclass=\"Arts\"\n",
    "                    elif fclass.startswith(\"Computer\") is True:\n",
    "                        fclass=\"Computer\"\n",
    "                    elif fclass.startswith(\"Flight\") is True:\n",
    "                        fclass=\"Flight\"\n",
    "                    else:\n",
    "                        raise ValueError(\"Don't understand {0} for {1}\".format(fclass, osm))\n",
    "\n",
    "                    geoid  = fclass\n",
    "                    enroll = record[30] ## Not used, but could\n",
    "\n",
    "\n",
    "                if fclass is None:\n",
    "                    #fclass = record[1]\n",
    "                    print(record)\n",
    "                    print(\"Don't know about {0}\".format(osm))\n",
    "                    break\n",
    "                \n",
    "            shapeData[geoid] = {\"Name\": fclass, \"Record\": irec}\n",
    "            cntr[geoid] += 1\n",
    "            #if irec > 1000: 1/0\n",
    "\n",
    "            ## Get Geohashs\n",
    "            geos  = getGeos(shape, prec=prec, returnKeys=True)\n",
    "            geoShapeMap[geoid] = geos\n",
    "            ngeos += len(geos)\n",
    "\n",
    "        print(\"Finished: {0}\".format(cntr.most_common(100)))\n",
    "        print(\"\\n\")\n",
    "            \n",
    "        if len(shapeData) > 0:\n",
    "            #for geoid in geoShapeMap.keys():\n",
    "            #    geoShapeMap[geoid] = list(geoShapeMap[geoid].keys())\n",
    "            print(\"Found {0} geos from {1}\".format(ngeos, shapeval))\n",
    "            saveGeoData(shapeData, geoShapeMap, Nshapes, ngeos, join(basedir, \"{0}-{1}\".format(osm, prec)))\n",
    "                ## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract /Users/tgadf/Downloads/OpenScience/AgriculturalMin.zip\n",
      "Directory: /Users/tgadf/Downloads/OpenScience/AgriculturalMin/AgriculturalMineralOperations\n",
      "      OSM: ['AgriculturalMineralOperations']\n",
      "AgriculturalMineralOperations\n",
      "Already processed this one...\n",
      "Current Time is Thu Nov 15, 2018 12:16:51 for \n",
      "\n",
      "Analyzing AgriculturalMineralOperations\tNone\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'geoid' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-48225d159998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mparseOS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mrmZipDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-76f7a38d66a3>\u001b[0m in \u001b[0;36mparseOS\u001b[0;34m(dirval, prec)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mshapeData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeoid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Record\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mirec\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mcntr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeoid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m#if irec > 1000: 1/0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'geoid' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from glob import glob\n",
    "from os import mkdir\n",
    "from os.path import splitext, basename, dirname, join, exists\n",
    "zipfiles = glob(join(basedir, \"*.zip\"))\n",
    "for zipname in zipfiles:\n",
    "    osdir = dirname(zipname)\n",
    "    name     = splitext(basename(zipname))[0]\n",
    "    dirval   = join(osdir, name) \n",
    "    if exists(dirval):\n",
    "        print(\"Directory {0} already exists\".format(dirval))\n",
    "        rmZipDir(dirval)\n",
    "        continue\n",
    "    try:\n",
    "        mkdir(dirval)\n",
    "    except:\n",
    "        pass\n",
    "    zip_ref = zipfile.ZipFile(zipname, 'r')\n",
    "    print(\"Extract {0}\".format(zipname))\n",
    "    zip_ref.extractall(dirval)\n",
    "    zip_ref.close()\n",
    "    \n",
    "    parseOS(dirval, prec)\n",
    "    \n",
    "    rmZipDir(dirval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "prec=7\n",
    "from glob import glob\n",
    "from os.path import basename,splitext, join\n",
    "from collections import Counter\n",
    "\n",
    "#mtypes   = set([splitext(basename(x))[0].split('-')[1] for x in vals])\n",
    "mtypes  = [\"traffic\", \"pofw\", \"pois\", \"transport\", \"buildings\"]\n",
    "mtypes  = [\"buildings\"]\n",
    "mtypes  = [\"pofw\"]\n",
    "mtypes  = [\"traffic\"]\n",
    "mtypes  = [\"transport\"]\n",
    "mtypes  = [\"pois\"]\n",
    "mtypes  = [\"traffic\", \"pofw\", \"pois\", \"transport\"]\n",
    "\n",
    "print(\"Mtypes --> {0}\".format(mtypes))\n",
    "for mtype in mtypes:\n",
    "    if mtype in [\"pofw\",\"traffic\",\"transport\",\"pois\"]:\n",
    "        vals    = glob(join(basedir, \"*-{0}-{1}-geos.p\".format(mtype, prec)))        \n",
    "        states  = set([splitext(basename(x))[0].split('-{0}'.format(mtype))[0] for x in vals])\n",
    "    else:\n",
    "        vals    = glob(join(basedir, \"*-{0}-geos.p\".format(prec)))\n",
    "        states  = set([splitext(basename(x))[0].split('-gis_osm')[0] for x in vals])\n",
    "    print(\"States --> {0}\".format(states))\n",
    "\n",
    "    print(\"============== {0} ==============\".format(mtype))\n",
    "    fnames = letters[:1]\n",
    "    for let in range(len(fnames)):\n",
    "        ngeosMtypes = 0\n",
    "        ngeos = 0\n",
    "        geomap  = {}\n",
    "        records = {}\n",
    "        cntr    = Counter()\n",
    "        for istate,state in enumerate(states):\n",
    "            if istate % len(fnames) != let:\n",
    "                continue\n",
    "            base = \"{0}*{1}*{2}\".format(state, mtype, prec)\n",
    "            recfiles = glob(join(basedir, \"{0}-data.p\".format(base)))\n",
    "            geofiles = glob(join(basedir, \"{0}-geos.p\".format(base)))\n",
    "\n",
    "            #print(\"  Found {0} and {1} rec/geo files for {2}\".format(len(recfiles), len(geofiles), mtype))\n",
    "            for i in range(len(geofiles)):\n",
    "                recfile = recfiles[i]\n",
    "                geofile = geofiles[i]\n",
    "\n",
    "                try:\n",
    "                    recdata = pickle.load(open(recfile, \"rb\"))\n",
    "                    geodata = pickle.load(open(geofile, \"rb\"))\n",
    "                    #print(\"Opened {0}\".format(recfile))\n",
    "                    #print(\"Opened {0}\".format(geofile))\n",
    "                except:\n",
    "                    print(\"Could not open {0}\".format(geofile))\n",
    "                    1/0\n",
    "                    continue\n",
    "\n",
    "                #print(geodata.keys())\n",
    "                #continue\n",
    "                ngeos = 0\n",
    "                for geoid,geos in geodata.items():\n",
    "                    ngeos += len(geos)\n",
    "                    ngeosMtypes += len(geos)\n",
    "                    for geo in geos:\n",
    "                        if geomap.get(geo) is None:\n",
    "                            geomap[geo] = Counter()\n",
    "                        #print(geo,mtype,geoid)\n",
    "                        #print(geoid)\n",
    "                        #print(recdata.keys())\n",
    "                        if recdata.get(geoid) is not None:\n",
    "                            try:\n",
    "                                #print(geoid)\n",
    "                                #print(recdata[geoid])\n",
    "                                #name = recdata[geoid]['Name']\n",
    "                                #print(name)\n",
    "                                name = geoid\n",
    "                            except:\n",
    "                                name = geoid\n",
    "                                #print(name)\n",
    "                        else:\n",
    "                            name = geoid\n",
    "                        cntr[name] += 1\n",
    "                        geomap[geo][name] += 1\n",
    "\n",
    "                for geoid,rec in recdata.items():\n",
    "                    records[geoid] = rec['Name']\n",
    "                    break\n",
    "\n",
    "            print(\"{0: <20}\\t{1: <20}\\t{2: <12}\\t{3: <12}\\t---> {4} <---\".format(mtype,state,ngeos,ngeosMtypes,len(geomap)))            \n",
    "        print(\"{0: <20}\\t{1: <20}\\t{2: <12}\\t{3: <12}\\t---> {4} <---\".format(mtype,\"\",\"\",ngeosMtypes,len(geomap)))\n",
    "\n",
    "        for k,v in cntr.most_common():\n",
    "            k = str(k)\n",
    "            if k.find(\" \") != -1 or k.find(\";\") != -1 or k.find(\"_\") != -1 or k.find(\",\") != -1 or k[0].isupper():\n",
    "                print(\"buildingConv[\\\"{0}\\\"] = \\\"{1}\\\"\".format(k, k))\n",
    "                found = True\n",
    "                    \n",
    "        for geo in geomap.keys():\n",
    "            geomap[geo] = dict(geomap[geo])\n",
    "        \n",
    "\n",
    "        fname=\"geomap-{0}-{1}OSM.p\".format(prec, mtype) #, fnames[let])\n",
    "        print(\"Writing {0}\".format(fname))\n",
    "        pickle.dump(geomap,  open(fname, \"wb\"))\n",
    "\n",
    "        fname=\"georec-{0}-{1}OSM.p\".format(prec, mtype) #, fnames[let])\n",
    "        print(\"Writing {0}\".format(fname))\n",
    "        pickle.dump(records,  open(fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = 7\n",
    "from glob import glob\n",
    "from os.path import join, basename\n",
    "show = False\n",
    "for zipfilename in zipfiles:\n",
    "    extractDir = unZipFile(zipfilename, test=False)\n",
    "    shapeDir   = extractDir\n",
    "    if True:\n",
    "        try:\n",
    "            shapeDir   = glob(join(extractDir, '*'))[0]\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    officialName = basename(shapeDir)\n",
    "    shapeval     = officialName\n",
    "    catID        = officialName\n",
    "    sf = getShapeData(shapeDir)\n",
    "    if sf is None:\n",
    "        print(\"Shapefile data is None!\")\n",
    "        rmZipDir(zipfilename)\n",
    "        continue\n",
    "    else:\n",
    "        print(\"  Shapefile data is ready to use\")\n",
    "        \n",
    "        \n",
    "    fields      = sf.fields\n",
    "    shapeData   = {}\n",
    "    geoShapeMap = {}\n",
    "    Nshapes     = len(sf.shapes())\n",
    "    totalgeos   = 0\n",
    "\n",
    "    start,cmt = clock(\"Analyzing {0}\\t{1}\".format(shapeDir, Nshapes))\n",
    "    if show:\n",
    "        print(\"\\n\\nFields -> {0}\".format(fields))\n",
    "\n",
    "    irec  = -1\n",
    "    ngeos = 0\n",
    "    \n",
    "    try:\n",
    "        sfIter = sf.iterShapeRecords()\n",
    "    except:\n",
    "        print(\"Could not iterate over shape records\")\n",
    "        rmZipDir(zipfilename)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    useLinear = False\n",
    "    for shapeRec in sfIter:\n",
    "        irec += 1\n",
    "        record = shapeRec.record\n",
    "        shape  = shapeRec.shape\n",
    "        points = shape.points\n",
    "        if len(points) == 1 or useLinear is True:\n",
    "            useLinear = True\n",
    "            geos = addLinearGeos(irec, Nshapes, shape, prec, debug=False)\n",
    "        else:\n",
    "            geos = getInitGeo(shape)\n",
    "            geos = addShapeGeos(irec, Nshapes, shape, prec, geos, debug=False)\n",
    "            if geos is None:\n",
    "                useLinear = True\n",
    "                geos = addLinearGeos(irec, Nshapes, shape, prec, debug=False)\n",
    "\n",
    "        ngeos += len(geos)\n",
    "        if shapeData.get(catID) is None:\n",
    "            shapeData[catID] = {}\n",
    "            shapeData[catID][catID]   = {\"Name\": officialName}\n",
    "            geoShapeMap[catID] = {}\n",
    "            geoShapeMap[catID][catID] = set()\n",
    "        for geo in geos:\n",
    "            geoShapeMap[catID][catID].add(geo)\n",
    "\n",
    "    if ngeos > 0:\n",
    "        print(\"Found {0} geos from {1}\".format(ngeos, shapeval))\n",
    "        saveGeoData(shapeData, geoShapeMap, Nshapes, ngeos, \"OpenScience/{0}-{1}\".format(shapeval, 7))\n",
    "        \n",
    "    rmZipDir(zipfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGeoRecData(basedir, vals, prec):\n",
    "    geomap  = {}\n",
    "    records = {}    \n",
    "    totalgeos = 0\n",
    "    for mtype in vals:\n",
    "        try:\n",
    "            recdata = pickle.load(open(\"{0}/{1}-{2}-data.p\".format(basedir, mtype, prec), \"rb\"))\n",
    "            geodata = pickle.load(open(\"{0}/{1}-{2}-geos.p\".format(basedir, mtype, prec), \"rb\"))\n",
    "        except:\n",
    "            print(\"Could not open files with base {0}/{1}-{2}\".format(basedir, mtype, prec))\n",
    "            continue\n",
    "        #print(\"--> {0} {1}\".format(len(recdata), len(geodata)))\n",
    "        ngeos = 0\n",
    "        for geoid,dummy in geodata.items():\n",
    "            for gdummy, geos in dummy.items():\n",
    "                ngeos += len(geos)\n",
    "                totalgeos += ngeos\n",
    "                for geo in geos:\n",
    "                    if geomap.get(geo) is None:\n",
    "                        geomap[geo] = {}\n",
    "                    geomap[geo][mtype] = geoid\n",
    "\n",
    "        for geoid,rec in recdata.items():\n",
    "            records[geoid] = mtype\n",
    "            #records[geoid] = rec['Name']\n",
    "            break\n",
    "\n",
    "        print(\"{0}\\t{1}\\t---> {2} <---\".format(mtype,ngeos,len(geomap)))\n",
    "        \n",
    "    print(\"Found {0} total geohashs\".format(totalgeos))\n",
    "    return geomap, records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues   = ['Arenas_NBA', 'Arenas_NCAA_Div_1_Basketball', 'Arenas_NHL', 'Arenas_WNBA', 'Stadiums_MLB', 'Stadiums_NCAA_Div_1_Football', 'Stadiums_NFL', 'State_Fairgrounds', 'Raceways_NASCAR', 'Tracks_Horses', 'Tracks_IRL']\n",
    "industry = ['AgriculturalMineralOperations', 'ConstructionMineralsOperations', 'CrushedStoneOpsUS', 'FerrousMetalMines', 'SandGravelMineralOps', 'FerrousMetalProcessingPlants', 'Mines', 'Nonferrous_Metal_Mines', 'RefractAbrasiveOtherIndMinOps', 'Uranium_Vanadium', 'MiscellaneousIndMineralOps']\n",
    "rail     = ['Rail_Points', 'Railroad', 'RRBRIDGES']\n",
    "car      = ['Bridges', 'TransitLine', 'TransitStation', 'Weigh_in_Motion_Stations', 'Automatic_Traffic_Counters', 'Tunnels']\n",
    "college  = ['CollegesUniversities']\n",
    "schools  = ['PrivateSchools', 'PublicSchools']\n",
    "commerce = ['Banks_Main_Offices', 'CorporateHeadquarters', 'CreditUnionsHQ', 'Pharmacies', 'UPSLocations', 'DHLLocations', 'FDIC_InsuredBanks', 'FedExLocations']\n",
    "terminal = ['CruiseLineTerminals', 'Ports', 'Navigable_Waterway_Nodes', 'Private_NonRetail_Shipping', 'Inland_Waterway_MM', 'Intermodal_Terminal_Facilities', 'Airports_Heliports']\n",
    "\n",
    "mtypes = {\"Venues\": venues, \"Industry\": industry, \"Rail\": rail, \"Car\": car, \"College\": college, \"Schools\": schools, \"Commerce\": commerce, \"Terminal\": terminal}\n",
    "\n",
    "vals    = glob(\"OpenScience/*-{0}-geos.p\".format(prec))\n",
    "vals    = [splitext(basename(x))[0].split('-')[0] for x in vals]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in venues]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in industry]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in rail]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in car]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in college]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in schools]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in commerce]\n",
    "print(len(vals))\n",
    "vals    = [x for x in vals if x not in terminal]\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mtype, vals in mtypes.items():\n",
    "    import pickle\n",
    "    prec=7\n",
    "    from glob import glob\n",
    "    from os.path import basename,splitext\n",
    "    #vals    = glob(\"OpenScience/*-{0}-geos.p\".format(prec))\n",
    "    #vals    = [splitext(basename(x))[0].split('-')[0] for x in vals]\n",
    "    print(vals)\n",
    "    geomap, records = getGeoRecData(\"OpenScience\", vals, prec)\n",
    "    print(geomap)\n",
    "    print(records.keys())\n",
    "    1/0\n",
    "    \n",
    "    fname=\"geomap-{0}-{1}.p\".format(prec, mtype)\n",
    "    print(\"Writing {0}\".format(fname))\n",
    "    pickle.dump(geomap,  open(fname, \"wb\"))\n",
    "\n",
    "    fname=\"georec-{0}-{1}.p\".format(prec, mtype)\n",
    "    print(\"Writing {0}\".format(fname))\n",
    "    pickle.dump(records,  open(fname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
